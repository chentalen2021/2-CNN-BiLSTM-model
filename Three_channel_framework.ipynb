{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import json\n",
    "from random import randint\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Read the IEMOCAP and EMODB feature set\n",
    "path_IEMOCAP_features = \"/Users/talen/Desktop/SER_Data/Audio_features_IEMOCAP.json\"\n",
    "path_EMODB_features = \"/Users/talen/Desktop/SER_Data/Audio_features_EMODB.json\"\n",
    "\n",
    "with open(path_IEMOCAP_features, \"r\") as fp1:\n",
    "    data1 = json.load(fp1)\n",
    "    \n",
    "# with open(path_EMODB_features, \"r\") as fp2:\n",
    "#     data2 = json.load(fp2)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the IEMOCAP feature sets\n",
    "def read_data(data, session_test_set, speaker_test_set):\n",
    "        \n",
    "    #Split the dataset into training, validation, and testing sets based on different speakers\n",
    "    sessions = [\"1\",\"2\",\"3\",\"4\",\"5\"]\n",
    "    speakers = [\"F\",\"M\"]\n",
    "\n",
    "    #Create the test set, including the predictors X and the target Y\n",
    "    X_test_LLDs = data[session_test_set][speaker_test_set][\"LLDs\"]\n",
    "    X_test_specs = data[session_test_set][speaker_test_set][\"Log-Mel-spectram\"]\n",
    "    X_test_smfcc = data[session_test_set][speaker_test_set][\"smfcc\"]\n",
    "    Y_test = data[session_test_set][speaker_test_set][\"class\"]\n",
    "    \n",
    "\n",
    "    X_test_LLDs_ori = data[session_test_set][speaker_test_set][\"LLDs_ori\"]\n",
    "    X_test_specs_ori = data[session_test_set][speaker_test_set][\"spectrogram_ori\"]\n",
    "\n",
    "\n",
    "\n",
    "    #Create the validation set similarly\n",
    "    if speaker_test_set == \"F\":\n",
    "        speaker_valid_set = \"M\"\n",
    "    else:\n",
    "        speaker_valid_set = \"F\"\n",
    "\n",
    "    X_valid_LLDs = data[session_test_set][speaker_valid_set][\"LLDs\"]\n",
    "    X_valid_specs = data[session_test_set][speaker_valid_set][\"Log-Mel-spectram\"]\n",
    "    X_valid_smfcc = data[session_test_set][speaker_valid_set][\"smfcc\"]\n",
    "    Y_valid = data[session_test_set][speaker_valid_set][\"class\"]\n",
    "\n",
    "\n",
    "    X_valid_LLDs_ori = data[session_test_set][speaker_valid_set][\"LLDs_ori\"]\n",
    "    X_valid_specs_ori = data[session_test_set][speaker_valid_set][\"spectrogram_ori\"]\n",
    "\n",
    "\n",
    "    #Create the training set similarly\n",
    "    X_train_LLDs = []\n",
    "    X_train_specs = []\n",
    "    X_train_smfcc = []\n",
    "    Y_train = []\n",
    "    \n",
    "    X_train_LLDs_ori=[]\n",
    "    X_train_specs_ori=[]\n",
    "\n",
    "    for session in sessions:\n",
    "        if session != session_test_set:\n",
    "            X_train_LLDs = X_train_LLDs + data[session][\"F\"][\"LLDs\"]+data[session][\"M\"][\"LLDs\"]\n",
    "            X_train_specs = X_train_specs + data[session][\"F\"][\"Log-Mel-spectram\"]+data[session][\"M\"][\"Log-Mel-spectram\"]\n",
    "            X_train_smfcc = X_train_smfcc + data[session][\"F\"][\"smfcc\"]+data[session][\"M\"][\"smfcc\"]\n",
    "            \n",
    "            Y_train = Y_train + data[session][\"F\"][\"class\"] + data[session][\"M\"][\"class\"]\n",
    "\n",
    "\n",
    "            X_train_LLDs_ori = X_train_LLDs_ori + data[session][\"F\"][\"LLDs_ori\"]+data[session][\"M\"][\"LLDs_ori\"]\n",
    "            X_train_specs_ori = X_train_specs_ori + data[session][\"F\"][\"spectrogram_ori\"]+data[session][\"M\"][\"spectrogram_ori\"]\n",
    "            \n",
    "    \n",
    "    return np.array(X_train_LLDs),np.array(X_train_LLDs_ori), np.array(X_train_specs), np.array(X_train_specs_ori),\\\n",
    "            np.array(X_train_smfcc), np.array(Y_train),np.array(X_valid_LLDs), np.array(X_valid_LLDs_ori), np.array(X_valid_specs),\\\n",
    "            np.array(X_valid_specs_ori), np.array(X_valid_smfcc), np.array(Y_valid),\\\n",
    "            np.array(X_test_LLDs), np.array(X_test_LLDs_ori), np.array(X_test_specs), np.array(X_test_specs_ori), np.array(X_test_smfcc), np.array(Y_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training, validation, and test sets for IEMOCAP dataset with regard to different speakers\n",
    "# training : validation : test = 8 : 1 : 1\n",
    "X_train_LLDs,X_train_LLDs_ori, X_train_specs, X_train_specs_ori, X_train_smfcc, Y_train, X_valid_LLDs,\\\n",
    "X_valid_LLDs_ori, X_valid_specs, X_valid_specs_ori, X_valid_smfcc, Y_valid, X_test_LLDs, X_test_LLDs_ori,\\\n",
    "X_test_specs, X_test_specs_ori , X_test_smfcc, Y_test = read_data(data1,\"4\",\"F\")\n",
    "\n",
    "X_train_specs = X_train_specs[...,np.newaxis]\n",
    "X_train_smfcc = X_train_smfcc[...,np.newaxis]\n",
    "X_valid_specs = X_valid_specs[...,np.newaxis]\n",
    "X_valid_smfcc = X_valid_smfcc[...,np.newaxis]\n",
    "X_test_specs = X_test_specs[...,np.newaxis]\n",
    "X_test_smfcc = X_test_smfcc[...,np.newaxis]\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training, validation, and test sets for IEMOCAP dataset in speaker-dependent style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use PCA to select the useful features in LLDs\n",
    "pca = PCA(n_components=128)\n",
    "X_train_LLDs_pca = X_train_LLDs.copy()\n",
    "X_valid_LLDs_pca = X_valid_LLDs.copy()\n",
    "X_test_LLDs_pca = X_test_LLDs.copy()\n",
    "\n",
    "X_train_LLDs_pca = pca.fit_transform(X_train_LLDs_pca)\n",
    "X_valid_LLDs_pca = pca.transform(X_valid_LLDs_pca)\n",
    "X_test_LLDs_pca = pca.transform(X_test_LLDs_pca)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the EMODB feature set\n",
    "\n",
    "#a. Define the method for loading spectrogram images\n",
    "root_EMODB_spectros = \"/Users/talen/Desktop/SER_Data/Spectrograms_EMODB/\"\n",
    "\n",
    "# b. load image data\n",
    "def load_img(path):\n",
    "    indices1=[]\n",
    "    indices2=[]\n",
    "    \n",
    "    imgs_EMD=[]\n",
    "    imgs_ori=[]\n",
    "    \n",
    "    for r, _, files in os.walk(path):\n",
    "        #iterate the spectrogram files\n",
    "        for file in tqdm(files):\n",
    "            if \".DS_Store\" not in file:\n",
    "                img = plt.imread(path+file, format=\"jpg\")\n",
    "\n",
    "                img_type = file.split(\".\")[0]\n",
    "                idx = int(file.split(\".\")[1])\n",
    "\n",
    "                if img_type == \"EMD\":\n",
    "                    imgs_EMD.append(img)\n",
    "                    indices1.append(idx)\n",
    "                else:\n",
    "                    imgs_ori.append(img)\n",
    "                    indices2.append(idx)\n",
    "    \n",
    "    #Create two dataframes for storing spectrograms of EMD-based and original respectively\n",
    "    df1 = pd.DataFrame({\n",
    "        \"idx\":indices1,\n",
    "        \"spectro_EMD\":imgs_EMD\n",
    "    })\n",
    "    \n",
    "    df2 = pd.DataFrame({\n",
    "        \"idx\":indices2,\n",
    "        \"spectro_ori\":imgs_ori\n",
    "    })\n",
    "    \n",
    "    #sort the spectrograms by their indices\n",
    "    df1.sort_values(by=\"idx\", ascending=True, inplace=True)\n",
    "    df2.sort_values(by=\"idx\", ascending=True, inplace=True)\n",
    "    \n",
    "    #Merge the two dataframes\n",
    "    df_spectro = pd.merge(df1, df2)\n",
    "    \n",
    "    return list(df_spectro[\"spectro_EMD\"]), list(df_spectro[\"spectro_ori\"])\n",
    "\n",
    "\n",
    "#b. Define the method for loading other audio features\n",
    "def read_data2(data, test_set_speaker):\n",
    "    #Split the dataset into training, validation, and testing sets based on different speakers\n",
    "        #'03', '08', '09', '10', '11', '12', '13', '14', '15', '16' are the ten speakers\n",
    "    speakers = [\"03\", \"08\", \"09\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\"]\n",
    "\n",
    "    #Create the test set, including the predictors X and the target Y\n",
    "        #LLDs_ori is the ComParE2016 feature set\n",
    "        #LLDs is the ComParE2016 feature set without 14MFCCs\n",
    "        #specs_ori is the log-mel-spectrograms\n",
    "        #specs is the log-mel-spectrograms extracted from signals with trend-removed\n",
    "    X_test_LLDs = data[test_set_speaker][\"LLDs\"]\n",
    "    X_test_smfcc = data[test_set_speaker][\"smfcc\"]\n",
    "\n",
    "    X_test_LLDs_ori = data[test_set_speaker][\"LLDs_ori\"]\n",
    "    X_test_specs, X_test_specs_ori = load_img(str(root_EMODB_spectros+test_set_speaker+\"/\"))\n",
    "    \n",
    "    Y_test = data[test_set_speaker][\"class\"]\n",
    "    \n",
    "\n",
    "    #Create the validation set similarly\n",
    "    speakers.remove(test_set_speaker)\n",
    "    valid_set_speaker = speakers[-1]\n",
    "    \n",
    "    X_valid_LLDs = data[valid_set_speaker][\"LLDs\"]\n",
    "    X_valid_smfcc = data[valid_set_speaker][\"smfcc\"]\n",
    "    \n",
    "    X_valid_LLDs_ori = data[valid_set_speaker][\"LLDs_ori\"]\n",
    "    X_valid_specs, X_valid_specs_ori = load_img(str(root_EMODB_spectros+valid_set_speaker+\"/\"))\n",
    "      \n",
    "    Y_valid = data[valid_set_speaker][\"class\"]\n",
    "\n",
    "\n",
    "    #Create the training set similarly\n",
    "    speakers.remove(valid_set_speaker)\n",
    "    \n",
    "    X_train_LLDs = []\n",
    "    X_train_specs = []\n",
    "    X_train_smfcc = []\n",
    "    Y_train = []\n",
    "    \n",
    "    X_train_LLDs_ori=[]\n",
    "    X_train_specs_ori=[]\n",
    "\n",
    "    for speaker in speakers:\n",
    "        X_train_LLDs = X_train_LLDs + data[speaker][\"LLDs\"]\n",
    "        X_train_smfcc = X_train_smfcc + data[speaker][\"smfcc\"]\n",
    "\n",
    "        Y_train = Y_train + data[speaker][\"class\"]\n",
    "        \n",
    "        X_train_LLDs_ori = X_train_LLDs_ori + data[speaker][\"LLDs_ori\"]\n",
    "        \n",
    "        specs, specs_ori = load_img(str(root_EMODB_spectros+speaker+\"/\"))\n",
    "        (X_train_specs, X_train_specs_ori) = (X_train_specs + specs, X_train_specs_ori + specs_ori)\n",
    "\n",
    "    return np.array(X_train_LLDs),np.array(X_train_LLDs_ori), np.array(X_train_specs), np.array(X_train_specs_ori),\\\n",
    "            np.array(X_train_smfcc), np.array(Y_train),np.array(X_valid_LLDs), np.array(X_valid_LLDs_ori), np.array(X_valid_specs),\\\n",
    "            np.array(X_valid_specs_ori), np.array(X_valid_smfcc), np.array(Y_valid),\\\n",
    "            np.array(X_test_LLDs), np.array(X_test_LLDs_ori), np.array(X_test_specs), np.array(X_test_specs_ori), np.array(X_test_smfcc), np.array(Y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the training, validation, and test sets for EMODB dataset\n",
    "# training : validation : test = 8 : 1 : 1\n",
    "\n",
    "X_train_LLDs2, X_train_LLDs_ori2, X_train_specs2, X_train_specs_ori2, X_train_smfcc2, Y_train2, X_valid_LLDs2,\\\n",
    "X_valid_LLDs_ori2, X_valid_specs2, X_valid_specs_ori2, X_valid_smfcc2, Y_valid2, X_test_LLDs2, X_test_LLDs_ori2 ,\\\n",
    "X_test_specs2, X_test_specs_ori2, X_test_smfcc2, Y_test2 = read_data2(data2,\"15\")\n",
    "\n",
    "\n",
    "X_train_smfcc2 = X_train_smfcc2[...,np.newaxis]\n",
    "X_valid_smfcc2 = X_valid_smfcc2[...,np.newaxis]\n",
    "X_test_smfcc2 = X_test_smfcc2[...,np.newaxis]\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_specs2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use PCA to select the useful features in LLDs\n",
    "pca2 = PCA(n_components=128)\n",
    "X_train_LLDs_pca2 = X_train_LLDs2.copy()\n",
    "X_valid_LLDs_pca2 = X_valid_LLDs2.copy()\n",
    "X_test_LLDs_pca2 = X_test_LLDs2.copy()\n",
    "\n",
    "X_train_LLDs_pca2 = pca2.fit_transform(X_train_LLDs_pca2)\n",
    "X_valid_LLDs_pca2 = pca2.transform(X_valid_LLDs_pca2)\n",
    "X_test_LLDs_pca2 = pca2.transform(X_test_LLDs_pca2)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Build the three-channel model\n",
    "#1.Build the model for HSF\n",
    "    #Create input layer\n",
    "        #6373 -> original HSF; 4973 -> HSF from trend-removed signal; 128 -> HSF after PCA\n",
    "input_HSF = keras.Input(shape=(128), name=\"HSF_layer\")\n",
    "    #1st FC layer\n",
    "features_HSF = keras.layers.Dense(units=1024, activation=\"sigmoid\")(input_HSF)\n",
    "    #2nd FC layer\n",
    "features_HSF = keras.layers.Dense(units=512, activation=\"sigmoid\")(features_HSF)\n",
    "    #3nd FC layer\n",
    "features_HSF = keras.layers.Dense(units=128, activation=\"sigmoid\")(features_HSF)\n",
    "\n",
    "features_HSF = keras.layers.Flatten()(features_HSF)\n",
    "features_HSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the additive attention model for training the CRNN\n",
    "#Source code cited from Keras attention tutorial (https://www.tensorflow.org/tutorials/text/nmt_with_attention)\n",
    "class BahdanauAttention(layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.k1 = layers.Dense(units=units)\n",
    "        self.k2 = layers.Dense(units=units)\n",
    "        self.V = layers.Dense(1)  #the V-scaler with 1 unit\n",
    "\n",
    "    def call(self, query, values):\n",
    "        #Expand the query with a time dimension in the second axis\n",
    "        #Then query shape -> (batch_size, time_step, hidden_state_size)\n",
    "        query_with_time_dim = tf.expand_dims(input=query, axis=1)\n",
    "\n",
    "        #score shape -> (batch_szie, time_step, 1)\n",
    "        #Calculate the attention scores by Bahdanau attention formula\n",
    "        # to take values, query and their weights into consideration\n",
    "        score = self.V(tf.nn.tanh(self.k1(values) + self.k2(query_with_time_dim)))\n",
    "\n",
    "        #attention weights shape -> (batch_size, time_step, 1)\n",
    "        #Calculate the attention distribution/weights\n",
    "        attention_weights = tf.nn.softmax(logits=score, axis=1)\n",
    "\n",
    "        #context_vector shape after sum -> (batch_size, hidden_state_size)\n",
    "        attention_outputs = attention_weights * values\n",
    "            #Sum the outputs across the second dimension\n",
    "        attention_outputs = tf.reduce_sum(attention_outputs, axis=1)\n",
    "\n",
    "        return attention_outputs, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1'. Define the UA metric to trace the model's performance over epochs\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class Unweighted_accuracy(Callback):\n",
    "    def __init__(self, model, validation_data, test_data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.validation_data = validation_data\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def on_epoch_end(self, epoch, log=None):\n",
    "        predi_valid = []\n",
    "        target_valid = self.validation_data[-1]\n",
    "        \n",
    "        for v in range(len(self.validation_data)-1):\n",
    "            predi_valid.append(self.validation_data[v])\n",
    "        \n",
    "        y_Pred_valid = np.argmax(self.model.predict(predi_valid), axis=1)\n",
    "        y_True_valid = target_valid\n",
    "        ua_valid = balanced_accuracy_score(y_True_valid, y_Pred_valid)\n",
    "        \n",
    "        \n",
    "        predi_test = []\n",
    "        target_test = self.test_data[-1]\n",
    "        \n",
    "        for t in range(len(self.test_data)-1):\n",
    "            predi_test.append(self.test_data[t])\n",
    "        \n",
    "        y_Pred_test = np.argmax(self.model.predict(predi_test), axis=1)\n",
    "        y_True_test = target_test\n",
    "        ua_test = balanced_accuracy_score(y_True_test, y_Pred_test)\n",
    "        \n",
    "        print(\"The UA over validation set is: \", np.round(ua_valid, decimals=4))\n",
    "        print(\"The UA over test set is: \", np.round(ua_test, decimals=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Build the model for log-mel-spectrogram\n",
    "    #Create input layer with the variable input size\n",
    "input_spec = keras.Input(shape=(X_test_specs2[0].shape[0], \n",
    "                               X_test_specs2[0].shape[1],\n",
    "                               X_test_specs2[0].shape[2]), name=\"spec_layer\")\n",
    "    #Create a CNN model\n",
    "    #Create 1st convolution layer, followed by a max-pooling layer and a BN layer\n",
    "kernerl_initialiser = tf.keras.initializers.TruncatedNormal(stddev=0.1)\n",
    "bias_initialiser = keras.initializers.Constant(value=0.1)\n",
    "\n",
    "features_cnn1=keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),padding=\"same\", \n",
    "                                  kernel_initializer=kernerl_initialiser, bias_initializer=bias_initialiser,\n",
    "                                  dilation_rate = 2)(input_spec)\n",
    "features_cnn1=keras.layers.BatchNormalization()(features_cnn1)\n",
    "features_cnn1=keras.layers.MaxPool2D(pool_size=(1, 2), strides=(1, 2), padding='valid')(features_cnn1)\n",
    "features_cnn1=keras.layers.LeakyReLU(0.01)(features_cnn1)\n",
    "features_cnn1_l1=keras.layers.Dropout(0.3)(features_cnn1)\n",
    "\n",
    "    #Create 2nd convolution layer, followed by a BN layer\n",
    "features_cnn1=keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),padding=\"same\", \n",
    "                                  kernel_initializer=kernerl_initialiser, \n",
    "                                  bias_initializer=bias_initialiser)(features_cnn1_l1)\n",
    "features_cnn1=keras.layers.BatchNormalization()(features_cnn1)\n",
    "features_cnn1_l2=keras.layers.MaxPool2D(pool_size=(1, 2), strides=(1, 2), padding='valid')(features_cnn1)\n",
    "\n",
    "    #Create a residual block for the above two\n",
    "# features_short_cut = keras.layers.Conv2D(128, (1,1), strides=)\n",
    "# block1 = keras.layers.add([input_spec, features_cnn1_l2])\n",
    "features_cnn1=keras.layers.LeakyReLU(0.01)(features_cnn1)\n",
    "features_cnn1=keras.layers.Dropout(0.3)(features_cnn1)\n",
    "\n",
    "    #Create 3rd convolution layer, followed by a BN layer\n",
    "features_cnn1=keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),padding=\"same\", \n",
    "                                  kernel_initializer=kernerl_initialiser, \n",
    "                                  bias_initializer=bias_initialiser)(features_cnn1)\n",
    "features_cnn1=keras.layers.BatchNormalization()(features_cnn1)\n",
    "features_cnn1=keras.layers.MaxPool2D(pool_size=(1, 2), strides=(1, 2), padding='valid')(features_cnn1)\n",
    "features_cnn1=keras.layers.LeakyReLU(0.01)(features_cnn1)\n",
    "features_cnn1_l3=keras.layers.Dropout(0.3)(features_cnn1)\n",
    "\n",
    "    #Create 4th convolution layer, followed by a BN layer\n",
    "features_cnn1=keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),padding=\"same\", \n",
    "                                  kernel_initializer=kernerl_initialiser, \n",
    "                                  bias_initializer=bias_initialiser)(features_cnn1_l3)\n",
    "features_cnn1=keras.layers.BatchNormalization()(features_cnn1)\n",
    "features_cnn1=keras.layers.MaxPool2D(pool_size=(1, 2), strides=(1, 2), padding='valid')(features_cnn1)\n",
    "features_cnn1=keras.layers.LeakyReLU(0.01)(features_cnn1)\n",
    "features_cnn1_l4=keras.layers.Dropout(0.3)(features_cnn1)\n",
    "\n",
    "\n",
    "\n",
    "    #Reshape the output of cnn to add time_steps\n",
    "features_cnn1_shaped = tf.reshape(features_cnn1,(-1,160,7392))\n",
    "\n",
    "    #Create Bi-LSTM layer to capture context info\n",
    "features_spec = keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=False),\n",
    "                                           merge_mode=\"concat\")(features_cnn1_shaped)\n",
    "    #Create attention layer\n",
    "# Attention1 = BahdanauAttention(units=100)\n",
    "# features_spec,_ = Attention1.call(query=features_spec, values=features_cnn1_shaped)\n",
    "\n",
    "    #Create FC layer to flatten the data into feature vector\n",
    "features_spec = keras.layers.Flatten()(features_spec)\n",
    "features_spec = keras.layers.Dense(units=128, activation=\"sigmoid\")(features_spec)\n",
    "features_spec = keras.layers.Dropout(0.3)(features_spec)\n",
    "\n",
    "features_cnn1_l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build the model only based on the spectrogram channel and test its performacne\n",
    "    #units=4 (4 emotion classes) -> IEMOCAP;  units=7 (7 emotion classes) -> EMODB\n",
    "result_spec = keras.layers.Dense(units=7, activation=\"softmax\", name=\"emotion_type\")(features_spec)\n",
    "\n",
    "model2 = keras.Model(inputs=input_spec, outputs=result_spec)\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ua = Unweighted_accuracy(model=model2, validation_data=(X_valid_specs_ori2, Y_valid2), \n",
    "                         test_data=(X_test_specs_ori2, Y_test2))\n",
    "\n",
    "model2.fit(\n",
    "    x=X_train_specs_ori2,\n",
    "    y=Y_train2,\n",
    "    validation_data=(X_valid_specs_ori2, Y_valid2),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[ua]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the UA of the CRNN for SER with Log-Mel-spectrogram\n",
    "predictions_spec = np.argmax(model2.predict(X_test_specs2), axis=1)\n",
    "ua = balanced_accuracy_score(y_true=Y_test2, y_pred=predictions_spec)\n",
    "ua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Build the model for SMFCC\n",
    "    #Create input layer\n",
    "input_smfcc = keras.Input(shape=(94,14,1), name=\"smfcc_layer\")\n",
    "    #Create a CNN model\n",
    "    #Create 1st convolution layer, followed by a max-pooling layer and a BN layer\n",
    "features_cnn2=keras.layers.Conv2D(filters=30, kernel_size=(2,2),activation=\"relu\", dilation_rate=2)(input_smfcc)\n",
    "features_cnn2=keras.layers.MaxPool2D(pool_size=(2,1), strides=(2,1), padding='valid')(features_cnn2)\n",
    "features_cnn2=keras.layers.BatchNormalization()(features_cnn2)\n",
    "    #Create 2nd convolution layer, followed by a max-pooling layer and a BN layer\n",
    "features_cnn2=keras.layers.Conv2D(filters=30, kernel_size=(2,2),activation=\"relu\", dilation_rate=2)(features_cnn2)\n",
    "features_cnn2=keras.layers.BatchNormalization()(features_cnn2)\n",
    "\n",
    "    #Reshape the output of cnn to add time_steps\n",
    "features_cnn2_shaped = tf.reshape(features_cnn2,(-1,150,88))\n",
    "\n",
    "    #Create Bi-LSTM layer to capture context info\n",
    "features_smfcc = keras.layers.Bidirectional(keras.layers.LSTM(units=128, return_sequences=True),\n",
    "                                           merge_mode=\"concat\")(features_cnn2_shaped)\n",
    "    #Create attention layer\n",
    "Attention1 = BahdanauAttention(units=100)\n",
    "features_smfcc,_ = Attention1.call(query=features_smfcc, values=features_cnn2_shaped)\n",
    "\n",
    "    #Create FC layer to flatten the data into feature vector\n",
    "features_smfcc = keras.layers.Flatten()(features_smfcc)\n",
    "features_smfcc = keras.layers.Dense(units=128, activation=\"sigmoid\")(features_smfcc)\n",
    "features_smfcc = keras.layers.Dropout(0.3)(features_smfcc)\n",
    "\n",
    "features_smfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Use a hidden (FC) layer to concatenate and reduce the dimensionality of the three types of output features above\n",
    "feature_vector = keras.layers.concatenate([features_HSF, features_spec, features_smfcc])\n",
    "\n",
    "#5. Output at softmax layer\n",
    "#units=4 (4 emotion classes) -> IEMOCAP;  units=7 (7 emotion classes) -> EMODB\n",
    "result = keras.layers.Dense(units=7, activation=\"softmax\", name=\"emotion_type\")(feature_vector)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Aggregate the three channels into one model\n",
    "model = keras.Model(\n",
    "    inputs=[input_HSF, input_spec, input_smfcc],\n",
    "    outputs=result,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#7. Compile and train the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "        \n",
    "\n",
    "unweighted_accuracy = Unweighted_accuracy(model=model, \n",
    "                                          validation_data=(X_valid_LLDs_pca2, X_valid_specs2, X_valid_smfcc2 ,Y_valid2),\n",
    "                                         test_data=(X_test_LLDs_pca2,X_test_specs2,X_test_smfcc2, Y_test2))\n",
    "\n",
    "model.fit(\n",
    "    x={\"HSF_layer\": X_train_LLDs_pca2, \"spec_layer\": X_train_specs2, \"smfcc_layer\": X_train_smfcc2},\n",
    "    y={\"emotion_type\": Y_train2},\n",
    "    validation_data=([X_valid_LLDs_pca2, X_valid_specs2, X_valid_smfcc2],Y_valid2),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[unweighted_accuracy]\n",
    ")\n",
    "\n",
    "#Calculate the UA of three-channel framework for SER\n",
    "predictions = np.argmax(model.predict(x=[X_test_LLDs_pca2,X_test_specs2,X_test_smfcc2]), axis=1)\n",
    "balanced_accuracy_score(y_true=Y_test2, y_pred=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the UA of three-channel framework for SER\n",
    "predictions = np.argmax(model.predict(x=[X_test_LLDs_pca2,X_test_specs2,X_test_smfcc2]), axis=1)\n",
    "balanced_accuracy_score(y_true=Y_test2, y_pred=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the UA of two-channel framework (by orignial LLDs and spectrogram based on signal trend removed)\n",
    "\n",
    "    #Concatenate the outputs from LLDs and spectrogram channels\n",
    "feature_vector_two = keras.layers.concatenate([features_HSF, features_spec])\n",
    "\n",
    "feature_vector_two = keras.layers.Dense(units=32, activation=\"sigmoid\")(feature_vector_two)\n",
    "\n",
    "    #Make classification by softmax\n",
    "result_two = keras.layers.Dense(units=7, activation=\"softmax\", name=\"emotion_type\")(feature_vector_two)\n",
    "\n",
    "\n",
    "model_two_channel = keras.Model(inputs=[input_HSF, input_spec], outputs=result_two)\n",
    "model_two_channel.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "\n",
    "\n",
    "model_two_channel.fit(\n",
    "    x={\"HSF_layer\": X_train_LLDs_ori2, \"spec_layer\": X_train_specs2},\n",
    "    y={\"emotion_type\": Y_train2},\n",
    "    validation_data=([X_valid_LLDs_ori2, X_valid_specs2],Y_valid2),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the UA of two-channel framework from orignial features\n",
    "predictions_ori = np.argmax(model_two_channel.predict(x=[X_test_LLDs_ori2,X_test_specs_ori2]), axis=1)\n",
    "balanced_accuracy_score(y_true=Y_test2, y_pred=predictions_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the WA\n",
    "error, acc=model_two_channel.evaluate(x=[X_test_LLDs_ori,X_test_specs_ori], y=Y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the mean and standard deviation\n",
    "\n",
    "specs_EMD = [0.287, 0.3266, 0.5111, 0.3852, 0.3348, 0.2744, 0.2875, 0.3448]\n",
    "three_channel_EMD = [0.4368, 0.4781, 0.3661, ]\n",
    "\n",
    "print(\"The mean is: \", np.mean(three_channel_EMD))\n",
    "print(\"The sd is: \", np.std(three_channel_EMD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
